<html lang="en-US">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1.0"/>
<title>International Workshop on Multimedia Content Generation and Evaluation: New Methods and Practice (McGE)</title>
 <meta name="description" content="Website for International Workshop on Multimedia Content Generation and Evaluation: New Methods and Practice (McGE) ---">
<link href="singlePageTemplate.css" rel="stylesheet" type="text/css">

</head>
<body>
<!-- Main Container -->

<div class="container"> 
  <!-- Navigation -->
  <header class="header" ><img class="mmimg" src="sigmmlogo.gif" />
    <nav>
      <ul>
        <li><a href="#homepage">Home</a></li>
        <li><a href="#call4paper">Call for Papers</a></li>
        <li><a href="#submission">Submission</a></li>
        <li> <a href="#dates">Important Dates</a></li>
        <li> <a href="#speakers">Speakers</a></li>
        <li> <a href="#organizers">Organizers</a></li>
      </ul>
    </nav>
</header>

	  <section id="homepage2">
<div align ="center"  style="position: relative; width: 100%;">
<img align ="center" class="pic" src="mcge_banner.jpeg" alt="">
  <div class = "title" ><strong>The 3rd International Workshop on Multimedia Content Generation and Evaluation: New Methods and Practice (McGE)</strong></div>


	 <div class = "title2" ><strong>This workshop is supported by the Innovation Center of Calligraphy and Painting Creation Technology, MCT, China.</strong></div>
    <!-- <div class = "title3" ><strong>In Conjunction with <a href="https://acmmm2025.org/" class="link" target="_blank">ACM MM 2025</a></strong></div><!-- 
    <!--  <div class = "title1" ><strong>Dublin, Ireland | 27 October - 31 October 2025</strong></div><!-- 
</div> 
</section>

  <section id="homepage">
<div class="stats">
  <h1><strong>Introduction</strong></h1>
</div>
<div class="stats_text">
    <p>Welcome to the homepage of the 3rd International Workshop on Multimedia Content Generation and Evaluation: New Methods and Practice (McGE)!</p>
    <p>The primary objectives of this workshop are as follows:</p>
    <p>To facilitate interdisciplinary discussions and collaborations among researchers and practitioners working on multimedia content generation, quality assessment, datasets, and construction.</p>
    <p>To present state-of-the-art research, novel techniques, and practical applications in multimedia content generation, including but not limited to image synthesis, video generation, text-to-image, and image-to-text conversion.</p>
    <p>To address challenges and explore new approaches in quality assessment of multimedia content, considering factors such as perceptual quality, semantic coherence, and technical quality.</p>
    <p>To discuss the development and evaluation of diverse and large-scale multimedia datasets, addressing issues such as data bias, annotation quality, and ethical considerations.</p>
    <p>To explore methods and tools for constructing effective multimedia datasets that can serve as benchmarks for the research community, driving innovation and progress in multimedia research.</p>
</div>
</section>

  <section id="call4paper">
<div class="stats">
    <h1><strong>Call for Papers</strong></h1>
</div>
<div class="stats_text">
    <p>
      We invite submissions for the Workshop on Multimedia Content Generation and Evaluation: New Methods and Practice to be held in conjunction with the ACM Multimedia 2025 conference. The workshop aims to bring together researchers and practitioners to discuss state-of-the-art research, novel techniques, and practical applications in multimedia content generation, quality assessment, datasets, and construction.
      The topics may include but are not limited to:
    </p>
    <ul class="stats_text_ul">
      Multimedia content generation:
      <li>Automatic image, video and audio generation technology</li>
      <li>Virtual reality and augmented reality content generation</li>
      <li>Semantic scene generation and synthesis</li>
      <li>Multimodal data fusion and representation</li>
      <p></p>

      Quality assessment:
      <li>Subjective and objective quality assessment methods</li>
      <li>Visual quality assessment based on human visual system</li>
      <li>Quality assessment of multimedia content compression and transmission</li>
      <li>Adaptive multimedia quality assessment</li>
      <li>Audio and video synchronization evaluation</li>
      <p></p>

      Datasets and construction tools
      <li>Public datasets for multimedia content generation and evaluation</li>
      <li>Data set expansion and data preprocessing technology</li>
      <li>Annotation and data mining tools</li>
      <li>Collection and organization of open source multimedia datasets</li>
      <li>Privacy and ethical issues of multimedia datasets</li>
      <li>Challenges and countermeasures of small samples and imbalanced datasets</li>
</li>

    </ul>
</div>
</section>

<section id="submission">
<div class="stats">
    <h1><strong>Paper Submission</strong></h1>
</div>

<div class="stats_text">
	<p>OpenReview website: https://openreview.net/group?id=acmmm.org/ACMMM/2025/Workshop/McGE</p>
    <p>After signing in the ACM MM 2025 submission site as the author, please choose our workshop name to submit the paper. Submissions can be of varying length from 4 to 8 pages, plus additional pages for the reference pages; i.e., the reference page(s) are not counted to the page limit of 4 to 8 pages. There is no distinction between long and short papers, but the authors may themselves decide on the appropriate length of the paper. All papers will be peer-reviewed by experts in the field, they will receive at least three reviews. Acceptance will be based on relevance to the workshop, scientific novelty, and technical quality. The workshop papers will be published in the ACM Digital Library.</p>
<p>Please refer to the main conference site for submission policies on blinding, originality, author lists and ArXiv publications.</p>
</div>

</section>

<section id="dates">
<div class="stats">
    <h1><strong>Important Dates</strong></h1>
</div>

<div class="stats_text">
    <ul  class="stats_text_ul">
      <li>Paper submission deadline: &nbsp&nbsp<del> <strong>&nbsp&nbsp July 5, 2025</strong></del> <strong>&nbsp&nbsp July 15, 2025</strong></li>
      <li>Notification of acceptance: &nbsp&nbsp <strong>&nbsp&nbsp&nbsp July 23, 2025</strong></li>
      <li>Camera ready submission: &nbsp&nbsp&nbsp <del><strong>&nbsp&nbsp August 2, 2025</strong></del><strong>&nbsp&nbsp August 8, 2025</strong></li>
      <li>Workshop Date (Hybrid): &nbsp&nbsp&nbsp <strong>&nbsp&nbsp&nbsp October 29, 2025</strong></li>
    </ul>
</div>
</section>
	
<section id="speakers" class="speakers">
  <div class="stats">
    <h1><strong>Keynote Speakers</strong></h1>
  </div>

  <div class="stats_text" align="left">
    <article class="speaker">
      <h2 class="speaker-name">Shahram Ghandeharizadeh</h2>
      <p class="speaker-affiliation">University of Southern California</p>
      <h3 class="talk-title">Flying Light Specks: Dronevision, Holodecks and Spatial Computing</h3>

      <h4>Biography</h4>
      <p>
        Shahram Ghandeharizadeh has been on the faculty of the USC Computer Science Department since 1990.
        In the mid 1990s when VHS and BETA tapes were dominant, his research group built Mitra, the first
        streaming software system with the ability to scale to multiple nodes. This groundbreaking system was
        later licensed by Panasonic for its research and development initiatives. In addition to Mitra, he has
        contributed to several pioneering systems, earning him the prestigious ACM Software System Award in 2008.
        FLS displays are the latest addition to his body of work, currently supported by two NSF grants. He is
        actively cultivating a collaborative academic network to expedite the research and realization of the
        Dronevision project. This includes the annual Holodecks Conference, with the next installment scheduled
        for January 8, 2026. See
        <a href="https://www.holodecks.quest" target="_blank" rel="noopener">https://www.holodecks.quest</a>
        for details.
      </p>

      <h4>Abstract</h4>
      <p>
        Since their introduction in 2021, the concept of 3D multimedia displays using Flying Light Specks (FLSs)
        has started to gain wider adoption. An FLS is a small drone configured with light sources and sensors that
        enable it to detect human touch [6]. A swarm of FLSs illuminates [3, 4, 7] 3D shapes and animations in a
        fixed volume that are visible to the naked eye and responsive to direct interaction with bare hands [2, 5, 9].
        They are a building block of desktop 3D multimedia displays, a Dronevision [1, 10], a room sized 3D
        multimedia display, a Holodeck [6], and our 3D world, Spatial Computing [8]. They complement existing
        Augmented Reality (AR) and eXtended Reality (XR) glasses. They shape the frontiers of multimedia systems
        research with the potential to revolutionize how we collaborate and work, learn and educate, design and
        manufacture, receive and deliver healthcare, and play and entertain.
      </p>
    </article>
  </div>
</section>



<section id="organizers">
  <div class="stats">
    <h1><strong>Workshop Organizers</strong></h1>
  </div>
<div align ="center" class="text-center_organizer">
  <div class="col-xs-2">
    <div class="people-name">
<p class="people-name-name"><a href="https://cjinfdu.github.io/" class="link" target="_blank">Prof. Cheng Jin</a></p>
<p class="people-name-inner">jc AT fudan.edu.cn</p>
      <p class="people-name-outer">Fudan University, China</p>
    </div>
  </div>



  <div class="col-xs-2">
    <div class="people-name">
<p class="people-name-name"><a href="https://person.zju.edu.cn/msong" class="link" target="_blank">Prof. Mingli Song</a></p>
<p class="people-name-inner">songml AT zju.edu.cn</p>
      <p class="people-name-outer">Zhejiang University, China</p>
    </div>
  </div>

  <div class="col-xs-2">
    <div class="people-name">
<p class="people-name-name"><a href="https://people.ucas.ac.cn/~wr" class="link" target="_blank">Prof. Rui Wang</a></p>
<p class="people-name-inner">wangrui AT iie.ac.cn</p>
      <p class="people-name-outer">University of Chinese Academy of Sciences, China</p>
    </div>
  </div>
  
  
    <div class="col-xs-2">
    <div class="people-name">
<p class="people-name-name"><a href="https://faculty.ecnu.edu.cn/_s49/wxj/main.psp" class="link" target="_blank">A/Prof. Xingjiao Wu</a></p>
<p class="people-name-inner">xjwu AT pharm.ecnu.edu.cn</p>
      <p class="people-name-outer">East China Normal University, China</p>
    </div>
  </div>

</div>

</section>
</div>
  <footer class="secondary_header footer">
<div class="copyright">&nbsp</div>
    <div class="copyright">&copy;2025 - <strong>ACM MM Workshop - McGE</strong></div>
<div class="copyright">&nbsp</div>
  </footer>
</body>

</html>
